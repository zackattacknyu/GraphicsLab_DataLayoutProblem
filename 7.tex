
\section{Conclusion and Future Work}

Given the data units, access requirements, and the desired upper bound on redundancy factor, we have proposed an algorithm that would create a cache oblivious layout with the primary goal of reducing the seek time through duplicating the data units. We propose a cost model for estimating the seek time, and in our algorithm we choose and copy data units in appropriate locations such that it reduces the estimated seek time.  We have shown that such a layout significantly improves both the performance and consistency of interactivity in massive model walkthrough applications.  \\
\\
Our proposed redundant storage of data may limit editing and modification of data because the data has to be modified at all copies. However, we foresee no problem in recomputing and updating the layout due to this modification using our algorithm since every iteration in our algorithm just assumes a layout and improves on it. After data modification, we can delete/modify the relevant data units, update the access pattern and run a few iterations of our algorithm to get a better layout. In other words, our algorithm is incremental and can be used for dynamic data sets also which might be a result of scene editing and modification.\\
\\
Our model for estimated seek time assumes equal usage of all access requirements. However, if we are given the information about usage statistics of each of the access requirements, the model can prioritize reduction of seek time of frequently used access requirements. Further, the set of data units that belong to an access requirement can also be refined to get better results. This can be done by checking the usage history of an application and group data units together if they are accessed together with high probability.

