//Data Structures

accessRequirement:
	- head, tail

dataUnitGroup:
	- set of data units that are adjacent
	- length will also be a field

dataUnit:
	- prev, next
	- forEachAR:
		-prev, next with same AR
		-dist to prev,next with same AR
	- ID
	- position

range tree for access requirements:
	- binary search tree of indices in first level
	- in next level are the endpoint positions

Main loop:
	Initialize benefitHeap
	for each accessRequirement P:
		add info (benefit, destination, chooseOldCopy, chooseNewCopy) from getARbenefitInfo to benefitHeap node
		do the same for the tail node routine
		order benefitHeap using benefit
	while there exists more space for redundancy:
		pop best element from benefitHeap, getting node,length,destination
		copy the elements node to node+length to destination
		for every access requirement P from destination to destination+length:
			update benefit info in heap
		for every access requirement T in chooseNewCopy:
			update head,tail info on access requirement
			update head node to not contain the old access requirement
		if chooseOldCopy is empty
			delete node
			for every accessRequirement P from node to node+length:
				update benefit info in heap
		reform Heap

Initial Analysis:
- n: number of ARs
- m: number of units per AR
- N: current total units
- L: length of AR
- Q: number of runs of redundancy loop
Initial construction analysis:
	Being run on n access requirements
	For each AR, there are log(n) operations to insert data into heap
	Let T_1(L) be running time to get the min number of affected access requirements
	For each AR, there are O(n + T_1(L)) operations to get benefit info.
	TOTAL: In worst case, initial construction takes O(n^2 + n T_1(L) )
Redundancy loop:
	Popping and copying takes O(1) operations
	There are O(n) access requirements affected by the operation
	Reforming the heap is O(n log n) operations
	Updating the positions takes O(N) operations
	TOTAL: In total, we have O(QN + Q*(n log n)) operations
TOTAL Running time:
	As stated above, there are O(n^2 + QN + Q(n logn) + n T_1(L)) operations

Analysis of findMinCut:
	Range tree approach with data units:
		Each node will have two bits of info (position,numARs)
		This info will be organized into a range tree
		Construction will be O(N log N)
		Query will be O(log N) if constructed so node contains min in other dimension
		New TOTAL run time: O(n^2 + QN + Q*(n log n) + n*logN + NlogN)
	Segment tree approach with AR info:
		Each AR is an interval
		This info will be organized into a segment tree
		Construction will be O(n log n)
		Query will be O(log n + n) since there are up to n possible results
			**TODO: Look into improving this running time if possible**
		New TOTAL run time: O(QN + Q*(n log n) + n^2 log n)
	Linear search approach:
		Each node will still have those two bits of info from range tree approach
		A query will linearly search through the nodes
		Construction will be O(N) and won't add anything to total
		Query will be O(L)
		New TOTAL run time: O(n^2 + QN + Q(n logn) + nL)
	Dynamic Programming approach:
		Store a matrix where each entry (i,j) contains the min from unit i to unit j
		It would require O(N^2) storage, which is unusable in our case
		Construction would be O(N^2)
			for every data unit i:
				for j from i+1 to N:
					matrix(i,j) gets min of matrix(i,j-1) and node j
		Query time would be O(1)
		New TOTAL run time: O(N^2 + QN + Q*(n log n) + n)

Analysis of list ordering:
	Dynamic numbers approach:
		Keep original position numbers same
		When inserting, use median of two numbers where it is being inserted
		Redundancy loop has O(1) for the update and just O(n log n) for reforming heap
		Initial construction though need to linearly search instead of automatically knowing positions
		Initial construction then will take O(n^2*L + n*T_1(L))
		TOTAL run time: O(n^2*L + Q(n logn) + n T_1(L)) operations
		TOTAL run time(letting n*L = O(N), n=O(N)): O(N^2 + Q(N log N) + N T_1(L))
	Current approach:
		TOTAL run time: O(n^2 + QN + Q(n logn) + n T_1(L)) operations
		TOTAL run time(letting n*L = O(N), n=O(N)): O(N^2 + Q(N log N) + N T_1(L))
	Conclusion:
		Current approach is fine as it does not really affect total run time
		


//subroutine for finding best spot
position findMinOverlappingARs(rangeTree for Access Requirement data, minPoint, maxPoint):
	search range tree to get nodes between minPoint and maxPoint
	min = Infinity
	For each node:
		update min if its min is better than the current one
	return position corresponding to min

number getLengthOfAdjacentUnitsHead(AccessRequirement T)
	length = 0
	start = T.head
	end = T.head.next
	while end.position – start.position = 1 //seems to measure number of adjacent units in the beginning of the AR
		length = length + 1
		start = start.next
		end = end.next
	return length,start,end

//subroutine for getting benefit of using AR
(benefit,destination,list chooseOldCopy, list chooseNewCopy) = getARbenefitInfo(accessRequirement P)
	//group adjacent units
	length,start,end = getLengthOfAdjacentUnitsHead(P)
	//this ends up being length between next data unit and the head. that is the potential that can be saved.
	potential = end.position – P.head.position - length
	//we are finding the best position between the "end" node and the tail of the access requirement.
	//putting the nodes before the end might reduce seek time, but we would reduce it better by putting it after the "end" node
	destination = findMinOverlappingARs(rangeTree, end.position, P.tail.position)
		-this should probably check both sides of the head/tail
		-this will take care of the corner case that Gopi pointed out
		-**TODO: Work out the details of this idea**
	benefit = potential
	//calculate cost to other ARs
	for each other AR uses the data units P.head to (P.head + length), T
		if P.head is T.head //in this case, they will both benefit
			T.length,T.start,T.end = getLengthOfAdjacentUnitsHead(T);
			//this gets us the benefit that we can guarantee, hence the min part
			benefit = benefit + min(potential, T.end.position – T.start.position)
			add T to chooseNewCopy list
		//in this case, we will definitely want the old copy
		else if any of the nodes in P.head to (P.head+length) is T.tail
			add T to chooseOldCopy list
		else
			//decide which copy to use in T
			if P.head is T.head.next
			{
				//difference1 is future benefit from using the new copy for T
				difference1 = P.end.position – P.start.position
				if destination > T.tail.prev.position
					//difference2 is future penalty from using the new copy for T
					difference2 = destination + length - T.tail.prev.position
					/* TODO: Figure out whether to consider P.length or T.length
					*/
				else
					difference2 = 0
				
				if difference1 > difference2
					add T to chooseNewCopy list
				else
					add T to chooseOldCopy list
			}
			else
				add T chooseOldCopy list
			
	if chooseOldCopy list is empty
		discard P.head
		for each AR, A
			if A.head.position < P.head.position AND A.tail.position > start.postion
				//by discarding, for each AR covering it, this is the benefit of deleting that data unit
				benefit = benefit + P.length

	